
# These will be dynamically updated using evaluate statements
# self.config refers to the API Configuration settings (this file + all other .yml files)
# rootDir is defined in user_path_definitions.yml
# Is a concatenation of all .yml and .ini configuration inputs

RelativePaths:
  # RelativePaths will dynamically added to a "Paths" section below using eval statements
  sourceDir: f"{self.config['rootDir']['Raw_HighFrequency_Data']}/{self.siteID}/raw/"
  metaDir: f"{self.config['rootDir']['Raw_HighFrequency_Data']}/{self.siteID}/metadata/"
  outputDir: f"{self.config['rootDir']['Raw_HighFrequency_Data']}/{self.siteID}/eddyProAPIOutputs/"
  baseEddyPro: f"{self.config['rootDir']['EddyPro']}/bin/"

metadataFiles:
  # Each section describes a separate csv file stored in metaDir
  # the key:value pairs are **kwargs for pandas to read the files
  fileInventory:
    parse_dates: [0]
    index_col: [0]
  rawDataStatistics:
    parse_dates: [0]
    index_col: [0]
    header: [0,1,2]
  metaDataValues:
    parse_dates: [0]
    index_col: [0]
    header: [0,1]
  configurationGroups:
    index_col: [0]
    header: [0,1,2]

# Kwargs fed to pandas for reading intermediate (rp) and final (fcc) output files
rpIntermediary:
  fluxnet:
    header: [0]
    parse_dates: [0]
    date_format: '%Y%m%d%H%M'
    keep_date_col: True
  biomet: 
    header: [0,1]
    parse_dates: [0,1]
    date_format: '%Y-%m-%d %H:%M'
    keep_date_col: True
fccFinalOutputs:
  full_output:
    header: [1,2]
    parse_dates: [1,2]
    date_format: '%Y-%m-%d %H:%M'

groupFiles:
  templateMetadata: f"{self.siteID}_{start}_{end}.metadata"
  groupMetaData: f"group_{groupID}_MetaData.metadata"
  eddyProCols: f"group_{groupID}_ColDefs.eddypro"

# Value for missing data in text columns
# Idea is to use a non-default NaN value so that text columns are preserved where desired
# Pandas defaults to object datatype with mixed string/NaN columns
stringTags:
  NaN: '~'
  exclude: _Exclude_
  groupID: f"group_{groupID}_"
intNaN: -9999

delimiters:
  # Valid delimiters that EddyPro can parse and corresponding asci representation
  comma: ','
  tab: '\t'
  semicolon: ';'
  space: ' '

biom_timestamp:
  name: TIMESTAMP_1
  format: '%Y-%m-%d %H%M'

# Calibration_Info:
#   # Set to True to include (only where it exists)
#   # Skipping will speed up
#   readCal:  True


monitoringInstructions:
  # Use wildcard matching to identify tags in metadata files and link them to header names in data files
  # Define how metadata and data files are monitored setup rules to filter/partition data
  # Metadata: (rules listed below)
  # Lists of keys by section which correspond to LICOR .metadata files, except Custom, which are generated by pre-processing
  # Rules
  #   groupBy: string values used to delineate site configurations, EddyPro runs will be partitioned by configurations
  #   track: numeric values that aggregated by groups but won't raise issues if they change between timestamps
  #   pass: representative value for a group is passed but statistics are not calculated
  #         * Changes of these values will *NOT* impact group splits
  metaData:
    groupBy:
      Site:
      - site_name
      - site_id
      Station:
      - station_name
      - station_id
      Timing:
      - acquisition_frequency
      - file_duration
      Instruments:
      - instr_*_manufacturer
      - instr_*_model
      - instr_*_sw_version
      - instr_*_id
      - instr_*_height
      - instr_*_wformat
      - instr_*_wref
      - instr_*_north_offset
      - instr_*_northward_separation
      - instr_*_eastward_separation
      - instr_*_vertical_separation
      - instr_*_vpath_length
      - instr_*_hpath_length
      - instr_*_tau
      - instr_*_tube_length
      - instr_*_tube_diameter
      - instr_*_kw
      - instr_*_ko
      FileDescription:
      - separator
      - header_rows
      - data_label
      - col_*_variable
      - col_*_instrument
      - col_*_measure_type
      - col_*_unit_in
      Custom:
      - col_*_header_name
    track:
      Site:
      - altitude
      - latitude
      - longitude
      - canopy_height
      - displacement_height
      - roughness_length
      Instruments:
      - '*_*_tube_flowrate'
    pass:
      FileDescription:
      - '*_*_min_value'
      - '*_*_max_value'
      - '*_*_conversion'
      - '*_*_unit_out'
      - '*_*_a_value'
      - '*_*_b_value'
      - '*_*_nom_timelag'
      - '*_*_min_timelag'
      - '*_*_max_timelag'
      Files:
      - data_path
      - saved_native
      - timestamp
      - iso_format
      - end_of_line
      - enable_processing
      - tstamp_end
      Project:
      - title
      - id
      - creation_date
      - last_change_date
      - start_date
      - end_date
      - file_name
      - sw_version
      - ini_version  
      Timing:
      - pc_time_settings
      
  dataAggregation:
    # Will yield the following statistics for raw traces when set to True
    # any trace set to ignore in the .metadata file will be ignored by default
    # them more stats generated, the larger the dataset, so use with caution
    # See options here: https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html#dataframegroupby-computations-descriptive-stats
    mean: True
    std: False
    median: False
    max: True
    min: True
    count: False

  # dataExclude:
  # - RECORD
  # - Seconds
  # - Nanoseconds
  # - Sequence Number
    
  dataFilters:
    Sonic_Filter:
      condition_1:
        variables: 
        - u
        - v
        - w
        measure_type: 
        filters:
          # Data here are aggregated statistics generated from the raw high frequency EC data
          # count: 10 # Eddypro default setting, maxiumum sample data % 
          # groupIX corresponds to the index of unique groups (as defined by metaData>groupBy above)
          # variables correspond to the list of variables defined for the corresponding condition (e.g., Sonic_Filter>condtion_1 defined above)
          # key (e.g., min, max, etc) MUST correspond to a statistic listed under dataAggregation defined above
          # filters can be given as a single string, or a list of different conditions
          min: Data.loc[groupIX,variables]<-100
          max: Data.loc[groupIX,variables]>100
    LI7200_Filter:
      condition_1:
        variables:
        - flowrate
        measure_type:
        filters:
          # This will flag anything with a mean flowrate < 10 lpm
          mean: Data.loc[groupIX,variables]<5
      condition_2:
        variables:
        - avg_signal_strength_7200
        measure_type:
        filters:
          mean: Data.loc[groupIX,variables]<60

eddyProGroupDefs:
  # Template for identifying relevant data file columns (by index #) for dumping into .eddypro files
  Project:
    col_co2:
      variable: co2
      measure_type:
      - mixing_ratio
      - molar_density
    col_h2o:
      variable: h2o
      measure_type:
      - mixing_ratio
      - molar_density
    col_ch4:
      variable: ch4
      measure_type:
      - mixing_ratio
      - molar_density
    col_n2o:
      variable: n2o
      measure_type:
      - mixing_ratio
      - molar_density
    col_int_t_1:
      variable: int_t_1
    col_int_t_2:
      variable: int_t_2
    col_int_p:
      variable: int_p
    col_air_t:
      variable: air_t
    col_air_p:
      variable: air_p
    col_cell_t:
      variable: cell_t
    col_diag_75:
      variable: diag_75
    col_diag_72:
      variable: diag_72
    col_diag_77:
      variable: diag_77
    col_diag_anem:
      variable: diag_anem
    col_ts:
      # this isn't sonic temperature, or at least I don't think so because it crashes when read as such
      # blocking for now, might be for thermocouples as alternate to ts?
      variable: idk?

  RawProcess_BiometMeasurements:
    biom_ta: Ta_1_1_1
    biom_pa: Pa_1_1_1
    biom_rh: RH_1_1_1
    biom_rg: Rg_1_1_1
    biom_lwin: LWIN_1_1_1
    biom_ppfd: PPFD_1_1_1

minDataReq:
  # EddyPro Settings that require a minimum batch size
  # Assumes batches are HH, can change to dynamic determination later if needed
  Project:
    hf_meth:
      '3': 1350
      '4': 1350
batchSize:
  max: 48
  min: 2